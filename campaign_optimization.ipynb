{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035e9120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044331</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044331 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in packages\n",
    "import itertools\n",
    "\n",
    "import datetime\n",
    "\n",
    "from test_results import test_results, score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load in the data\n",
    "train_data = pd.read_csv('./training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea0181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>41851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>41643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Promotion  purchase  count\n",
       "0        No         0  41851\n",
       "1        No         1    319\n",
       "2       Yes         0  41643\n",
       "3       Yes         1    721"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Promotion','purchase'])['ID'].count().reset_index().rename({'ID':'count'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cdd3e9",
   "metadata": {},
   "source": [
    "# 1. First analyze the difference in purchase rates between the control group and experimental group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670fbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_evaluation_metrics(n_control, \n",
    "                        n_exper, \n",
    "                        p_null, \n",
    "                        p_click_control,\n",
    "                        p_click_exper,\n",
    "                        alt=\"larger\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Statistical test to determine if we reached our goal;\n",
    "    \n",
    "    Input:\n",
    "        n_control: size of control group\n",
    "        n_exper: size of experiment group\n",
    "        p_click_control: goal hit rate for control group\n",
    "        p_click_exper: goal hit rate for experiment group\n",
    "        alt: the relationship between p_click_control and p_click_exper in alternative hypothesis;\n",
    "             larger: p_click_exper > p_click_control\n",
    "             small: p_click_exper < p_click_control\n",
    "             different: p_click_exper is not equal to p_click_control\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute standard error, z-score, and p-value\n",
    "    se_p = np.sqrt(p_null * (1-p_null) * (1/n_control + 1/n_exper))\n",
    "    z = (p_click_exper - p_click_control) / se_p\n",
    "    if alt == \"larger\":\n",
    "        p_result = 1-stats.norm.cdf(z)\n",
    "    elif alt == \"smaller\":\n",
    "        p_result = stats.norm.cdf(z)\n",
    "    elif alt == \"different\":\n",
    "        p_result = 2 * stats.norm.cdf(-abs(z))\n",
    "    print(\"Success rate for control group: {}; Success rate for experiment group: {}\".format(round(p_click_control, 4), round(p_click_exper, 4)))\n",
    "    print(\"p value: {}\".format(round(p_result, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7137167e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate for control group: 0.0076; Success rate for experiment group: 0.017\n",
      "p value: 0.0\n"
     ]
    }
   ],
   "source": [
    "p_evaluation_metrics(sum(train_data['Promotion'] == \"No\"),\n",
    "                     sum(train_data['Promotion'] == \"Yes\"),\n",
    "                     train_data['purchase'].mean(),\n",
    "                     train_data[train_data['Promotion'] == \"No\"]['purchase'].mean(),\n",
    "                     train_data[train_data['Promotion'] == \"Yes\"]['purchase'].mean(),\n",
    "                     alt=\"different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c365705",
   "metadata": {},
   "source": [
    "# Functon for evaluating data processing, model evaluation and tuning\n",
    "\n",
    "Our metrics IRR and NIR, all emphasize the idea that we will not only look for increasing the conversions, but also optimizing the ad cost. A very important strategy is to avoid sending ads to customers who are more likely to buy even without seeing the ad and customers who are not likely to buy even when they see the ad. It's ideal to send ads to customers who might not feel interested before they see the ad, but have high chances to convert after they see the ad.\n",
    "\n",
    "Also, when training the model we have to deal with the imbalance in data. As we can see from the analysis above, the conversion rate is very low --- even for experiment group that's 1.7%. If we don't deal with this issue, our model could predict every sample as negative --- the accuracy will still be 98%!\n",
    "\n",
    "To handle data imbalance, we upsample the purchase group and downsample the non-purchase group seperately for control and experiment group --- the sizes of the resampled groups are also tunable. Also, when we split the training data to train set and validation set (usually known as train_test_split), we did a stratified sampling to avoid the senario where there's no positive records in validation set and to make sure that the validation set is close to a real world testing data.\n",
    "\n",
    "When tuning the model, we focused mostly on the loss from errors rather than gainings from giving the ads to the right people. It actually worked quite well in the end. More details can be founded in the docstring in the function evaluate. The reason why we didn't consider true positives here to \"reward\" the model is that when we trained the models, we greatly balanced the data --- we greatly upsampled the purchase group and only sample a little (no more than 10%) from non-purchase group , so we can expect that recall is usually higher than precision. In other words, our model might have done its best to recognize the customers who will make purchases but it can be over optimistic. We want to correct that since giving promotion ads to too many people can greatly increase the cost of the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721eeb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_train_test_split(data,\n",
    "                               tag_col,\n",
    "                               minority_tag_value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Do train_test_split on minority group and majority group seperately\n",
    "    -- sample 20% minority and 20% majority to the final test set\n",
    "    \n",
    "    This process doesn't drop any columns\n",
    "    \n",
    "    Input:\n",
    "        data: the data to split\n",
    "        tag_col: column for the class label\n",
    "        minority_tag_value: class label that has very few representatives\n",
    "    \"\"\"\n",
    "    \n",
    "    data_minor = data[data[tag_col] == minority_tag_value]\n",
    "    data_major = data[data[tag_col] != minority_tag_value]\n",
    "    \n",
    "    train_minor, test_minor = train_test_split(data_minor, test_size=0.2)\n",
    "    train_major, test_major = train_test_split(data_major, test_size=0.2)\n",
    "    \n",
    "    train = pd.concat([train_minor, train_major]).sample(frac=1)\n",
    "    test = pd.concat([test_minor, test_major]).sample(frac=1)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3faa7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampler(data, \n",
    "              tag_col,\n",
    "              minority_tag_value,\n",
    "              minority_group_size,\n",
    "              majority_group_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Handle the imbalanced data\n",
    "    \n",
    "    For minority group we upsample the data with replacement; \n",
    "    For majority group we downsample the data without replacement;\n",
    "    \n",
    "    This process doesn't drop any columns\n",
    "    \n",
    "    Input:\n",
    "        data: the data to split\n",
    "        tag_col: column for the class label\n",
    "        minority_tag_value: class label that has very few representatives\n",
    "        minority_group_size: group size of the minority group after resampling\n",
    "        majority_group_size: group size of the majority group after resampling\n",
    "    \"\"\"\n",
    "    \n",
    "    minority_resample = resample(data[data[tag_col] == minority_tag_value], \n",
    "                                 replace=True,\n",
    "                                 n_samples=minority_group_size)\n",
    "    majority_resample = resample(data[data[tag_col] != minority_tag_value], \n",
    "                                 replace=False,\n",
    "                                 n_samples=majority_group_size)\n",
    "    resampled_data = pd.concat([minority_resample, majority_resample])\n",
    "    return resampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fb5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, learning_rate=0.1, max_depth=10, min_samples_split=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    A general function for a machine learning pipeline of \n",
    "    (1) scaling all the variables\n",
    "    (2) training a GradientBoostingClassifier with specified parameters\n",
    "    \n",
    "    The model returned is a trained Pipeline object\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = GradientBoostingClassifier(learning_rate=learning_rate, \n",
    "                                 max_depth=max_depth, \n",
    "                                 min_samples_split=min_samples_split)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85c115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    A general function for checking the f1, precision and recall score of the model;\n",
    "    Actually we won't use it since we will have different scoring function for tuning the model,\n",
    "    but when building the model we might want to have a look at these more \"traditional\" scorings \n",
    "    to understand how our model is performing\n",
    "    \n",
    "    Output is a dictionary with 'precision', 'recall' and 'f1'\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    result = {}\n",
    "    result['precision'] = precision_score(y, y_pred)\n",
    "    result['recall'] = recall_score(y, y_pred)\n",
    "    result['f1'] = f1_score(y, y_pred)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46683999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_full(train, \n",
    "                     minority_group_size, \n",
    "                     majority_group_size, \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=10, \n",
    "                     min_samples_split=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    A general function of of resampling the data and training a model.\n",
    "    \n",
    "    Input:\n",
    "        train: the training data (after train_test_split)\n",
    "        minority_group_size: group size of the minority group after resampling\n",
    "        majority_group_size: group size of the majority group after resampling\n",
    "        learning_rate: parameter for GradientBoostingClassifier \n",
    "        max_depth: parameter for GradientBoostingClassifier \n",
    "        min_samples_split: parameter for GradientBoostingClassifier \n",
    "    \"\"\"\n",
    "    \n",
    "    re_train = resampler(train, \"purchase\", 1, minority_group_size, majority_group_size)\n",
    "    X = re_train[['V1','V2','V3','V4','V5','V6','V7']]\n",
    "    y = re_train['purchase']\n",
    "    model = train_model(X, \n",
    "                        y, \n",
    "                        learning_rate=learning_rate, \n",
    "                        max_depth=max_depth, \n",
    "                        min_samples_split=min_samples_split)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_promotion_customer_list(data,\n",
    "                                     data_to_predict,\n",
    "                                     control_minority_group_size,\n",
    "                                     control_majority_group_size,\n",
    "                                     expr_minority_group_size,\n",
    "                                     expr_majority_group_size,\n",
    "                                     learning_rate=0.1, \n",
    "                                     max_depth=10, \n",
    "                                     min_samples_split=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train 2 models to predict whether a customer will buy the product:\n",
    "    --- one on control group and another one on experiemnt group\n",
    "    \n",
    "    Predict with the 2 models:\n",
    "    --- result from the model trained on control group: whether a customer\n",
    "        will purchase if they don't see the ad\n",
    "    --- result from the model trained on experiment group: whether a customer\n",
    "        will purchase if they see the ad\n",
    "        \n",
    "    This function might not be well named :) Because it doesn't directly generate the \n",
    "    promotion customer list. \n",
    "    \n",
    "    Input:\n",
    "        data: the training data (after train_test_split)\n",
    "        data_to_predict: testing data or validation data\n",
    "        control_minority_group_size: group size of the purchase control group after resampling\n",
    "        control_majority_group_size: group size of the non-purchase control group after resampling\n",
    "        expr_minority_group_size: group size of the purchase experiment group after resampling\n",
    "        expr_majority_group_size: group size of the non-purchase experiment group after resampling\n",
    "        learning_rate: parameter for GradientBoostingClassifier \n",
    "        max_depth: parameter for GradientBoostingClassifier \n",
    "        min_samples_split: parameter for GradientBoostingClassifier \n",
    "        \n",
    "    \n",
    "    The output is the table data_to_predict with 2 extra columns:\n",
    "        purchase without ad: whether a customer will purchase if they don't see the ad\n",
    "        purchase with ad: whether a customer will purchase if they see the ad\n",
    "    \"\"\"\n",
    "    \n",
    "    model1 = train_model_full(data[data['Promotion'] == \"No\"],\n",
    "                              control_minority_group_size,\n",
    "                              control_majority_group_size,\n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=max_depth, \n",
    "                              min_samples_split=min_samples_split)\n",
    "    \n",
    "    y1 = model1.predict(data_to_predict[['V1','V2','V3','V4','V5','V6','V7']])\n",
    "    \n",
    "    data_to_predict['purchase without ad'] = y1\n",
    "    \n",
    "    model2 = train_model_full(data[data['Promotion'] == \"Yes\"],\n",
    "                              expr_minority_group_size,\n",
    "                              expr_majority_group_size,\n",
    "                              learning_rate=learning_rate, \n",
    "                              max_depth=max_depth, \n",
    "                              min_samples_split=min_samples_split)\n",
    "    \n",
    "    y2 = model2.predict(data_to_predict[['V1','V2','V3','V4','V5','V6','V7']])\n",
    "    \n",
    "    data_to_predict['purchase with ad'] = y2\n",
    "    \n",
    "    return data_to_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e0c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred_pd):\n",
    "    \n",
    "    \"\"\"\n",
    "    We mainly focus on the loss (rather than the people we successfully predicted that will make purchase)\n",
    "    \n",
    "    ### Check control group\n",
    "    If we predict that the customer will buy without ad but actually they didn't buy\n",
    "     -> under this case we won't promote to the customer\n",
    "     ---- if the customer won't buy either after seeing the ad then we are fine;\n",
    "     ---- if the customer will buy after seeing the ad then we are losing $(10 - 0.15) --> Based on the data from \n",
    "          the previous round, 1.7% of the people who saw ads will buy \n",
    "    if we predict that the customer won't buy without ad but actually they bought\n",
    "     -> we actually don't need to promote to the customer but if we also predict that they will buy with the ad we \n",
    "        will end up promote to them. Then we are losing $0.15\n",
    "        \n",
    "    ### Check experiment group\n",
    "    if we predict that the customer will buy with the ad but actually they didn't \n",
    "     ---- if we also predict that they will buy without the ad then we are fine\n",
    "     ---- if not, we are giving them the ad while we don't need to. Then we are losing $0.15\n",
    "    if we predict that the customer won't buy with the ad but they bought\n",
    "     -> under this case we won't give them the ad. \n",
    "     ---- if the customer won't buy without ad --> we should've gave them the ad --> we are losing $(10 - 0.15) -->\n",
    "          (100% - 0.76%) of the people won't buy without ad\n",
    "     ---- if the customer will buy without ad then we are fine\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred_control = y_pred_pd[y_pred_pd['Promotion'] == \"No\"]\n",
    "    y_pred_expr = y_pred_pd[y_pred_pd['Promotion'] == \"Yes\"]\n",
    "    \n",
    "    loss = 0.017 * (10 - 0.15) * sum((y_pred_control['purchase without ad'] == 1) & \\\n",
    "                                     (y_pred_control['purchase'] == 0)) + \\\n",
    "           0.15 * sum((y_pred_control['purchase without ad'] == 0) & \\\n",
    "                      (y_pred_control['purchase'] == 1) & \\\n",
    "                      (y_pred_control['purchase with ad'] == 1)) + \\\n",
    "           0.15 * sum((y_pred_expr['purchase with ad'] == 1) & \\\n",
    "                      (y_pred_expr['purchase'] == 0) & \\\n",
    "                      (y_pred_expr['purchase without ad'] == 0)) + \\\n",
    "           (1 - 0.0076) * (10 - 0.15) * sum((y_pred_expr['purchase with ad'] == 0) & \\\n",
    "                                            (y_pred_expr['purchase'] == 1)) \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ce25e",
   "metadata": {},
   "source": [
    "## 3. Tune the model --- find the best parameters\n",
    "\n",
    "Parameters for us train include:\n",
    "\n",
    "**control_minority_group_size:** group size of the purchase control group after resampling<br>\n",
    "**control_majority_group_size:** group size of the non-purchase control group after resampling<br>\n",
    "**expr_minority_group_size:** group size of the purchase experiment group after resampling<br>\n",
    "**expr_majority_group_size:** group size of the non-purchase experiment group after resampling<br>\n",
    "**learning_rate:** parameter for GradientBoostingClassifier<br>\n",
    "**max_depth:** parameter for GradientBoostingClassifier<br>\n",
    "**min_samples_split:** parameter for GradientBoostingClassifier<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdaa5e",
   "metadata": {},
   "source": [
    "## 3.1 Split our original data train_data to trainning set and testing set\n",
    "\n",
    "In each dataset, control group data and experiment data are mixed together because there's a column Promotion to indicate whether a record is in one group or another. Later in our functions we will be able to split them.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110d5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_train, control_test = customize_train_test_split(train_data[train_data['Promotion'] == \"No\"], \"purchase\", 1)\n",
    "expr_train, expr_test = customize_train_test_split(train_data[train_data['Promotion'] == \"Yes\"], \"purchase\", 1)\n",
    "train = pd.concat([control_train, expr_train])\n",
    "test = pd.concat([control_test, expr_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe9bd6",
   "metadata": {},
   "source": [
    "# 3.2 Specify the candidate values for each variable and create a list of all combinations of the values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a912a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_minority_group_size = [1000, 1200]\n",
    "control_majority_group_size = [2000, 3000]\n",
    "expr_minority_group_size = [3000, 4000]\n",
    "expr_majority_group_size = [4000, 5000]\n",
    "learning_rate = [0.01, 0.02]\n",
    "max_depth = [6, 8]\n",
    "min_samples_split = [2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a77a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(itertools.product(*[control_minority_group_size, \n",
    "                         control_majority_group_size,\n",
    "                         expr_minority_group_size,\n",
    "                         expr_majority_group_size,\n",
    "                         learning_rate,\n",
    "                         max_depth,\n",
    "                         min_samples_split]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b316e",
   "metadata": {},
   "source": [
    "# 3.3 Gridsearch on the variables\n",
    "\n",
    "For each parameter combination, we run generate_promotion_customer_list 5 times and then calculate average loss. This is an approximate methods to 5 folds cross validation. Rather than spliting the data to 5 folds ahead and use one fold as validation set at one time, we randomly split data each time we run the model. This might be the laziness of the author :) and can be improved by 5 folds validation in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7631882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time: 3e+01 min\n",
      "Minimum average loss: 1021.753772\n",
      "Best params : (1000, 3000, 4000, 4000, 0.01, 6, 4)\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "begin = datetime.datetime.now()\n",
    "for p in params: \n",
    "    l = []\n",
    "    for i in range(5):\n",
    "        y_pred_pd = generate_promotion_customer_list(train,\n",
    "                                                     test,\n",
    "                                                     p[0],\n",
    "                                                     p[1],\n",
    "                                                     p[2],\n",
    "                                                     p[3],\n",
    "                                                     p[4],\n",
    "                                                     p[5])\n",
    "        l.append(evaluate(y_pred_pd))\n",
    "\n",
    "    loss_list.append(l)\n",
    "time_pass = (datetime.datetime.now() - begin).seconds / 60\n",
    "print(\"running time: {:.2} min\".format(time_pass))\n",
    "average_loss_list = list(np.mean(np.array(loss_list), axis=1))\n",
    "print(\"Minimum average loss: {}\".format(min(average_loss_list)))\n",
    "best_params = params[average_loss_list.index(min(average_loss_list))]\n",
    "print(\"Best params : {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31877d77",
   "metadata": {},
   "source": [
    "3.4 The best parameters and minimum average loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19326e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss_list = list(np.mean(np.array(loss_list), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4f80c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021.753772"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minimum average loss\n",
    "min(average_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5179a2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.017985611510791366,\n",
       " 'recall': 0.023923444976076555,\n",
       " 'f1': 0.02053388090349076}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(train_model_full(train[train['Promotion'] == \"No\"], \n",
    "                     1200, \n",
    "                     2000, \n",
    "                     learning_rate=0.01, \n",
    "                     max_depth=6, \n",
    "                     min_samples_split=2),\n",
    "                test[['V1','V2','V3','V4','V5','V6','V7']],\n",
    "                test['purchase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa7d25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.016669147194522994,\n",
       " 'recall': 0.5358851674641149,\n",
       " 'f1': 0.03233256351039261}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(train_model_full(train[train['Promotion'] == \"Yes\"], \n",
    "                     10000, \n",
    "                     10000, \n",
    "                     learning_rate=0.01, \n",
    "                     max_depth=6, \n",
    "                     min_samples_split=2),\n",
    "                test[['V1','V2','V3','V4','V5','V6','V7']],\n",
    "                test['purchase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1eb5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    \n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "    \n",
    "    y_pred_pd = generate_promotion_customer_list(train_data,\n",
    "                                     df,\n",
    "                                     best_params[0],\n",
    "                                     best_params[1],\n",
    "                                     best_params[2],\n",
    "                                     best_params[3],\n",
    "                                     learning_rate=best_params[4], \n",
    "                                     max_depth=best_params[5], \n",
    "                                     min_samples_split=best_params[6])\n",
    "    \n",
    "    result = np.array(((y_pred_pd['purchase without ad'] == 0) & (y_pred_pd['purchase with ad'] == 1))\\\n",
    "             .apply(lambda x: \"Yes\" if x else \"No\"))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0e40e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0189.\n",
      "\n",
      "Your nir with this strategy is 347.70.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01894361672172826, 347.70000000000005)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f00cc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the model for 10 times\n",
      "Distributions of irr and nir:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_results_distributions(promotion_strategy, numbers_run=10):\n",
    "    print(\"Run the model for {} times\".format(numbers_run))\n",
    "    test_data = pd.read_csv('Test.csv')\n",
    "    df = test_data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']]\n",
    "    irrs = []\n",
    "    nirs = []\n",
    "    for i in range(numbers_run):\n",
    "        promos = promotion_strategy(df)\n",
    "        score_df = test_data.iloc[np.where(promos == 'Yes')]    \n",
    "        irr, nir = score(score_df)\n",
    "        irrs.append(irr)\n",
    "        nirs.append(nir)\n",
    "    print(\"Distributions of irr and nir:\")\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(irrs)\n",
    "    a1=plt.title('irr')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(nirs)\n",
    "    a1=plt.title('nir')\n",
    "\n",
    "test_results_distributions(promotion_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad1f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
